---
layout: page
title: "Predicting Crime Types in Boston Area"
description: "Aiming for a safer city"
header-img: "img/home-bg.jpg"
---

# Overview

For this final project, we examined the public available data from Boston Police Department (BPD). We are going to focus on two main goals: 1) Understanding the geographical and temporal crime pattern in Boston, as well as evaluating if the crime categories are related with certain situational or environmental factors 2) Forecasting the types of criminal misconduct in Boston at night, with the ultimate goal to help the Police Department with a model that offers insightful information to better control the crime rate.

# Motivation

Based on FBI crime data, in 2018, Boston ranked 14 out of 50 in the US with regard to crime rate(FBI, 2018). The chance of being a victim of either violent or property crime in Boston is as high as 1 in 34, which makes Boston more violent than cities such as New York and Seattle(NeighborhoodScout, 2019). Even though Boston crime statistics demonstrate an overall downward trend in violent and property crimes in the past years, the city’s crime rate is still a lot higher than the national average crime rate.

Considering that the Boston Police Department has limited resources to foot patrol and guard a wide range of areas at night. Under this circumstance, distributing the limited intervention capacity to the most needed location is of great importance. If we are able to use data analytics to forecast the types of crime misconduct of each district at a certain time, the Boston Police will have better visibility on allocate manpower with targeted preparation. For this project we are also interested to see if certain situational and environmental features are linked with crime types. Understanding this context in which violence occurs has broad applicability to public policies on violence mitigation. The project result will hopefully help BPD to design a more effective intervention program to reduce the crime rate at night.

# Initial investigation

With the goal to build a prediction model, we first investigated factors that are associated with crime and crime types. The first factor is street lights. There is a controversy around the argument whether street lights would affect crime rate and if it is associated with types of crime occurred. Lighting has the potential to change crime in by enhancing visibility, empowering victims for better self-defense and exposing offenders to public witnesses. One randomized trial conducted in New York has demonstrated the effectiveness of street lights in reducing violent crime(Chalfin, Hansen, Lerner, & Parker, 2019).  A meta-analysis of 13 papers conducted by Welsh and Farrington (2008) reports that, crime rate drop by 27 percent with the addition of street lighting. These results suggest street light might have a differential effect on incidence of different crime types.

Another factor is property value. Even though there is a lack of research on the impact of property value on crime rate or crime types, multiple research has found significant effects of crime rate on property values and especially high-end properties. In the U.S, top decile of zip codes in terms of crime reduction in the 1990s, has led to a property value increase of 7–19% between 1990 and 2000 (Pope & Pope, 2012). Senick’s spatial analysis (2018) reports that the presence of crimes is more damaging to property value the closer they are to the property, and importantly, the violent crimes tend to have larger impact on property value than property crime. The property value seems to be quite responsive to rate of certain crime types and therefore we could use it as one feature to predict crime type.

In addition, in a study of crimes conducted in the Boston area, Weathersby (1970) reported a significant influence of population size on crimes against properties, whereas it does not exert impact on crime against persons. However, there are also conflicting evidence that shows weak to none correlation between population density and crimes. One study of Carol (1971) estimated partial correlations between crime rates and population density and found there is a negative relationship for certain crime types (murder, rape and assult), whereas the correlation is positive for robbery. However, none of the correlation significant. We decided to incorporate population density as a potential socioeconomic feature to our prediction model given there is a certain degree of evidence supporting its association with crimes.

# Potential Methods for Improving the Performance of Multi-Class Classification

To solve a classification task, the ultimate goal is to make as many accurate predictions as possible. The goodness of a model and the quality of the classifier might be evaluated by many metrics, with accuracy as one of the most common measures. However, the task is not always easy and can get even more complex when the target variable is multiclass, since the classifier has to distinguish a number of classes to make the prediction. In the last decades, people have made many efforts in the hope of improving the performance of classifiers. A lot of different approaches have been proposed, and they mostly fell into the following three general classes: 1) more efficient overall design of learning techniques, 2) transformation of training data at the upstream stage, and 3) modifications and adjustments of predictions generated by the classifier at the downstream stage under the assumption of independent class labels (Silva-Palacios, Ferri, & Ramírez-Quintana, 2017). An example of class 1 might be *Ensemble Learning*, a concept based on the idea of gathering and using a number of algorithms, and encompassing various techniques to achieve the predictive performance that can outcompete the capability of any individual constituent model. Decision trees with bagging(Breiman, 1996) or boosting(Freund & Schapire, 1997) is one specific case of the methods belonging to this class. With regard to class 2, there exists a lot of approaches based on feature selection (e.g. LASSO) as well as algorithms employing oversampling or undersampling methods to deal with imbalanced datasets (e.g. SMOTE) (Blagus & Lusa, 2013). Lastly, applying threshold choice methods(Hernandez-Orallo, Flach, & Ferri, n.d.) or classifier calibration techniques(Zadrozny & Elkan, 2002) to scoring models are some examples for group 3. For this project, we may consider one of the approaches mentioned above if the performance of our baseline model is not ideal.

# Challenges

Data processing was a very challenging task in this project. Although the datasets we used were mostly found on one single open data hub *Analyze Boston*, there were subtle variations in how these different data were encoded and recorded. For instance, in the Street Lights dataset, geographic coordinates were given as the measure of location, while in the Property Value dataset, only street names and zip codes were provided. Even though streets and coordinates were all included in the crime incident reports, connecting these three datasets was obstructed due to inconsistent naming and abbreviations of the streets across the different data. Thus, recoding for a unified column of street names was required prior to data merging. This work was almost impossible to be automated and demanded a lot of manual checking to achieve completion.

In addition, the task of our final project is to conduct multi-class classification, while most data we used in the past assignments had binary outcomes as response variable. The complexity of our final dataset (imbalanced outcomes, independent variables from very different sources) further increased difficulties when it came to model building.

Finally, our data contained more than 100,000 observations, and the computing power of local laptops became a limiting factor during the process of data cleaning and modelling. For example, when we were creating the column `Dist_to_Nearest_Light`, the main challenge we were facing was that per-pair calculations of the distances between all the street lights (more than 70000 observations) and all the crime locations (more than 140000 observations) took extremely long time to run (big shout out to our TF Abhi who helped us with his time-saving solution). Similarly, despite the fact that training and test accuracies still exhibited an increasing trend in our neural network model, we had no choice but restrict the number of epochs to 1000 due to limited computing power.
